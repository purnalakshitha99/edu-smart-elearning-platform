{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (3.11.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\isuru\\anaconda3\\envs\\new\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\" \n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    inputs = [\"generate question: \" + context for context in examples[\"context\"]]\n",
    "    targets = [question for question in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.5 * len(tokenized_datasets[\"train\"]))  \n",
    "validation_size = int(0.5 * len(tokenized_datasets[\"validation\"])) \n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].select(range(train_size))\n",
    "validation_dataset = tokenized_datasets[\"validation\"].select(range(validation_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Isuru\\AppData\\Local\\Temp\\ipykernel_1732\\2659337235.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  0%|          | 0/27375 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "  0%|          | 2/27375 [00:15<60:02:46,  7.90s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 26\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\accelerate\\accelerator.py:2241\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2241\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5, \n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,  \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\", \n",
    "    report_to=\"none\"  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "train_output = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "df_logs = pd.DataFrame(logs)\n",
    "\n",
    "train_loss = df_logs[df_logs[\"loss\"].notnull()][\"loss\"]\n",
    "eval_loss = df_logs[df_logs[\"eval_loss\"].notnull()][\"eval_loss\"]\n",
    "steps = df_logs[df_logs[\"loss\"].notnull()][\"step\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, train_loss, label=\"Training Loss\", color=\"blue\")\n",
    "plt.plot(steps, eval_loss[:len(steps)], label=\"Validation Loss\", color=\"orange\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if \"eval_accuracy\" in df_logs.columns:\n",
    "    eval_accuracy = df_logs[df_logs[\"eval_accuracy\"].notnull()][\"eval_accuracy\"]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(steps, eval_accuracy[:len(steps)], label=\"Validation Accuracy\", color=\"green\")\n",
    "    plt.title(\"Validation Accuracy Over Steps\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./t5-qna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./t5-qna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./t5-qna\")\n",
    "tokenizer.save_pretrained(\"./t5-qna\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Question: What was the name of each Super Bowl game?\n",
      "Generated Answer: Super Bowl 50\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-qna\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-qna\")\n",
    "\n",
    "context = \"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the 'golden anniversary' with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as Super Bowl L, so that the logo could prominently feature the Arabic numerals 50.\"\n",
    "\n",
    "input_question = f\"generate question: {context}\"\n",
    "input_ids_question = tokenizer.encode(input_question, return_tensors=\"pt\")\n",
    "\n",
    "outputs_question = model.generate(input_ids_question, max_length=50, num_beams=4, early_stopping=True)\n",
    "question = tokenizer.decode(outputs_question[0], skip_special_tokens=True)\n",
    "\n",
    "input_answer = f\"answer the question: {question} context: {context}\"\n",
    "input_ids_answer = tokenizer.encode(input_answer, return_tensors=\"pt\")\n",
    "\n",
    "outputs_answer = model.generate(input_ids_answer, max_length=50, num_beams=4, early_stopping=True)\n",
    "answer = tokenizer.decode(outputs_answer[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Question:\", question)\n",
    "print(\"Generated Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./t5-qna\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./t5-qna\")\n",
    "\n",
    "def generate_questions(context, model, tokenizer):\n",
    "    input_text = f\"generate question: {context}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import string\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"./t5-qna\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./t5-qna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(chunk, model, tokenizer):\n",
    "    input_text = f\"generate question: {chunk}\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=5, early_stopping=True, temperature=0.6)\n",
    "\n",
    "    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(context, query):\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=8, early_stopping=True, temperature=0.5)\n",
    "    \n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    if answer == query:\n",
    "        answer = \"The answer is unclear, please try again.\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_and_generate_questions_with_context(pdf_path, model, tokenizer, max_context_length=1024):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    chunks = [text[i:i + max_context_length] for i in range(0, len(text), max_context_length)]\n",
    "\n",
    "    qa_pairs = []\n",
    "    for chunk in chunks:\n",
    "        question = generate_questions(chunk, model, tokenizer)\n",
    "        \n",
    "        answer = predict(chunk, question)\n",
    "\n",
    "        qa_pairs.append({\"context\": chunk, \"question\": question, \"answer\": answer})\n",
    "\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Isuru\\anaconda3\\envs\\new\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: In what century did the steam engine revolutionize transportation and industry?\n",
      "Context: The evolution of technology has been one of the most significant factors shaping human history.\n",
      "From the advent of the wheel to the rise of artificial intelligence (AI), technology has played a pivotal\n",
      "role in the progress of society. In ancient times, humans developed basic tools to make their lives\n",
      "easier, but it was during the industrial revolution that technological advancements began to rapidly\n",
      "transform the world. The invention of the steam engine, for example, revolutionized transportation\n",
      "and industry, leading to an era of mass production and global trade.\n",
      "The 20th century saw an explosion of technological breakthroughs. The invention of the telephone,\n",
      "radio, and television changed the way humans communicated and interacted. The development of\n",
      "computers and the internet has been equally transformative, enabling a level of connectivity and\n",
      "information-sharing that was previously unimaginable. Today, we are living in an age of digital\n",
      "technology, where smartphones, cloud computing, and artificial intell\n",
      "Predicted Answer: 20th century\n",
      "\n",
      "Question 2: What is the potential of AI to improve efficiency and solve complex problems?\n",
      "Context: igence are integral parts of daily\n",
      "life.\n",
      "Artificial intelligence is one of the most exciting and rapidly evolving fields in technology today. AI\n",
      "refers to machines that can perform tasks that typically require human intelligence, such as learning,\n",
      "reasoning, and problem-solving. AI systems can analyze vast amounts of data to identify patterns\n",
      "and make predictions, which has applications in fields ranging from healthcare to finance to\n",
      "entertainment. The potential of AI to improve efficiency and solve complex problems is vast, but it\n",
      "also raises important ethical and societal questions about privacy, job displacement, and the control\n",
      "of autonomous systems.\n",
      "One area where technology is making a major impact is in healthcare. Advances in medical\n",
      "technology, such as robotic surgery, diagnostic imaging, and telemedicine, are improving patient\n",
      "outcomes and making healthcare more accessible. Additionally, biotechnology and genomics are\n",
      "opening up new possibilities for personalized medicine, allowing for treatments ta\n",
      "Predicted Answer: What is the potential of AI to improve efficiency?\n",
      "\n",
      "Question 3: What is the name of the internet of things?\n",
      "Context: ilored to anindividual's genetic makeup. These technologies hold great promise, but they also present\n",
      "challenges, such as ensuring equitable access and addressing concerns about privacy and data\n",
      "security.\n",
      "The internet of things (IoT) is another technological development that is transforming the way we\n",
      "live. IoT refers to the network of connected devices that communicate with each other and share\n",
      "data. Smart homes, wearable devices, and connected cars are all examples of IoT applications.\n",
      "These technologies are making life more convenient and efficient, but they also raise concerns\n",
      "about security and the potential for privacy violations. As IoT devices become more ubiquitous, it will\n",
      "be crucial to ensure that they are secure and that user data is protected.\n",
      "The rise of automation and robotics is another major technological trend that is reshaping industries\n",
      "around the world. Robots are increasingly being used in manufacturing, agriculture, and even\n",
      "healthcare to perform tasks that were once done by humans. Whi\n",
      "Predicted Answer: IoT\n",
      "\n",
      "Question 4: What is the potential for le automation to increase efficiency and reduce costs?\n",
      "Context: le automation has the potential to\n",
      "increase efficiency and reduce costs, it also raises concerns about job displacement and the future\n",
      "of work. As robots and AI systems take on more tasks, it will be important to find ways to retrain\n",
      "workers and ensure that they have the skills needed for the jobs of the future.\n",
      "In the realm of energy, renewable energy technologies are advancing rapidly. Solar and wind power\n",
      "are becoming more affordable and efficient, and new technologies like energy storage and smart\n",
      "grids are helping to integrate these renewable sources into the existing energy infrastructure. The\n",
      "shift toward renewable energy is crucial in the fight against climate change, but it also presents\n",
      "challenges, such as the need for investment in new infrastructure and the potential impact on\n",
      "traditional energy industries.\n",
      "Space exploration is another area where technology is making significant strides. Advances in\n",
      "rocket technology, satellite communication, and space telescopes are allowing humans to explorethe \n",
      "Predicted Answer: What is the potential for le automation to increase efficiency?\n",
      "\n",
      "Question 5: What technology is changing the way we interact with our environment?\n",
      "Context: cosmos like never before. Private companies like SpaceX are making space travel more\n",
      "affordable and accessible, with the goal of eventually enabling human settlement on other planets.\n",
      "The potential for space exploration to unlock new scientific discoveries and resources is immense,\n",
      "but it also presents challenges, such as the ethical implications of colonizing other planets and the\n",
      "environmental impact of space exploration.\n",
      "As technology continues to advance, the line between the physical and digital worlds is becoming\n",
      "increasingly blurred. Technologies like augmented reality (AR) and virtual reality (VR) are changing\n",
      "the way we experience and interact with our environment. These technologies have applications in\n",
      "entertainment, education, and even therapy, offering new ways to engage with information and\n",
      "people. However, they also raise questions about the potential for addiction, social isolation, and the\n",
      "impact on mental health.\n",
      "Cybersecurity is another critical issue in today's technology-driven world. As \n",
      "Predicted Answer: augmented reality\n",
      "\n",
      "Question 6: How many aspects of our lives move online?\n",
      "Context: more aspects of our\n",
      "lives move online, the threat of cyberattacks and data breaches has become a major concern.\n",
      "Hackers can exploit vulnerabilities in computer systems to steal sensitive information, disrupt\n",
      "services, or cause financial damage. Protecting against cyber threats requires constant innovation in\n",
      "security technologies, as well as collaboration between governments, businesses, and individuals to\n",
      "ensure that data is secure and that privacy is maintained.\n",
      "The rapid pace of technological change also presents challenges for education and workforce\n",
      "development. As new technologies emerge, workers need to acquire new skills to remain\n",
      "competitive in the job market. Education systems must adapt to prepare students for the jobs of the\n",
      "future, which may require a greater focus on STEM (science, technology, engineering, and\n",
      "mathematics) education, as well as the development of critical thinking and problem-solving skills.\n",
      "Lifelong learning and upskilling will become increasingly important as technology contin\n",
      "Predicted Answer: more\n",
      "\n",
      "Question 7: What is the power of technology to create positive change on a global scale?\n",
      "Context: ues to\n",
      "evolve.One of the most exciting aspects of technology is its potential to solve some of the world's most\n",
      "pressing problems. From addressing climate change to improving access to education and\n",
      "healthcare, technology has the power to create positive change on a global scale. However, it is\n",
      "important to approach technological innovation with caution, ensuring that it is used ethically and\n",
      "responsibly to benefit society as a whole.\n",
      "As we look to the future, it is clear that technology will continue to evolve and shape the world in\n",
      "ways we can only begin to imagine. The key to harnessing its potential lies in our ability to balance\n",
      "progress with responsibility, ensuring that the benefits of technology are shared by all and that its\n",
      "challenges are addressed in a thoughtful and inclusive manner.\n",
      "The evolution of technology has been one of the most significant factors shaping human history.\n",
      "From the advent of the wheel to the rise of artificial intelligence (AI), technology has played a pivotal\n",
      "role in the pro\n",
      "Predicted Answer: Technology has the power to create positive change on a global scale\n",
      "\n",
      "Question 8: When did the steam engine revolution revolutionize transportation and industry?\n",
      "Context: gress of society. In ancient times, humans developed basic tools to make their lives\n",
      "easier, but it was during the industrial revolution that technological advancements began to rapidly\n",
      "transform the world. The invention of the steam engine, for example, revolutionized transportation\n",
      "and industry, leading to an era of mass production and global trade.\n",
      "The 20th century saw an explosion of technological breakthroughs. The invention of the telephone,\n",
      "radio, and television changed the way humans communicated and interacted. The development of\n",
      "computers and the internet has been equally transformative, enabling a level of connectivity and\n",
      "information-sharing that was previously unimaginable. Today, we are living in an age of digital\n",
      "technology, where smartphones, cloud computing, and artificial intelligence are integral parts of daily\n",
      "life.\n",
      "Artificial intelligence is one of the most exciting and rapidly evolving fields in technology today. AIrefers to machines that can perform tasks that typically require human in\n",
      "Predicted Answer: The 20th century saw an explosion of technological breakthroughs\n",
      "\n",
      "Question 9: What is the potential of AI to improve efficiency and solve complex problems?\n",
      "Context: telligence, such as learning,\n",
      "reasoning, and problem-solving. AI systems can analyze vast amounts of data to identify patterns\n",
      "and make predictions, which has applications in fields ranging from healthcare to finance to\n",
      "entertainment. The potential of AI to improve efficiency and solve complex problems is vast, but it\n",
      "also raises important ethical and societal questions about privacy, job displacement, and the control\n",
      "of autonomous systems.\n",
      "One area where technology is making a major impact is in healthcare. Advances in medical\n",
      "technology, such as robotic surgery, diagnostic imaging, and telemedicine, are improving patient\n",
      "outcomes and making healthcare more accessible. Additionally, biotechnology and genomics are\n",
      "opening up new possibilities for personalized medicine, allowing for treatments tailored to an\n",
      "individual's genetic makeup. These technologies hold great promise, but they also present\n",
      "challenges, such as ensuring equitable access and addressing concerns about privacy and data\n",
      "security.\n",
      "The internet\n",
      "Predicted Answer: What is the potential of AI to improve efficiency?\n",
      "\n",
      "Question 10: What is the name of the network of connected devices that communicate with each other?\n",
      "Context:  of things (IoT) is another technological development that is transforming the way we\n",
      "live. IoT refers to the network of connected devices that communicate with each other and share\n",
      "data. Smart homes, wearable devices, and connected cars are all examples of IoT applications.\n",
      "These technologies are making life more convenient and efficient, but they also raise concerns\n",
      "about security and the potential for privacy violations. As IoT devices become more ubiquitous, it will\n",
      "be crucial to ensure that they are secure and that user data is protected.\n",
      "The rise of automation and robotics is another major technological trend that is reshaping industries\n",
      "around the world. Robots are increasingly being used in manufacturing, agriculture, and even\n",
      "healthcare to perform tasks that were once done by humans. While automation has the potential to\n",
      "increase efficiency and reduce costs, it also raises concerns about job displacement and the future\n",
      "of work. As robots and AI systems take on more tasks, it will be important to find\n",
      "Predicted Answer: IoT\n",
      "\n",
      "Question 11: What is the potential for space exploration?\n",
      "Context:  ways to retrainworkers and ensure that they have the skills needed for the jobs of the future.\n",
      "In the realm of energy, renewable energy technologies are advancing rapidly. Solar and wind power\n",
      "are becoming more affordable and efficient, and new technologies like energy storage and smart\n",
      "grids are helping to integrate these renewable sources into the existing energy infrastructure. The\n",
      "shift toward renewable energy is crucial in the fight against climate change, but it also presents\n",
      "challenges, such as the need for investment in new infrastructure and the potential impact on\n",
      "traditional energy industries.\n",
      "Space exploration is another area where technology is making significant strides. Advances in\n",
      "rocket technology, satellite communication, and space telescopes are allowing humans to explore\n",
      "the cosmos like never before. Private companies like SpaceX are making space travel more\n",
      "affordable and accessible, with the goal of eventually enabling human settlement on other planets.\n",
      "The potential for space explorati\n",
      "Predicted Answer: What is the potential for space explorati?\n",
      "\n",
      "Question 12: Who can exploit vulnerabilities in computer systems to steal information?\n",
      "Context: on to unlock new scientific discoveries and resources is immense,\n",
      "but it also presents challenges, such as the ethical implications of colonizing other planets and the\n",
      "environmental impact of space exploration.\n",
      "As technology continues to advance, the line between the physical and digital worlds is becoming\n",
      "increasingly blurred. Technologies like augmented reality (AR) and virtual reality (VR) are changing\n",
      "the way we experience and interact with our environment. These technologies have applications in\n",
      "entertainment, education, and even therapy, offering new ways to engage with information and\n",
      "people. However, they also raise questions about the potential for addiction, social isolation, and the\n",
      "impact on mental health.\n",
      "Cybersecurity is another critical issue in today's technology-driven world. As more aspects of our\n",
      "lives move online, the threat of cyberattacks and data breaches has become a major concern.\n",
      "Hackers can exploit vulnerabilities in computer systems to steal sensitive information, disruptservices, \n",
      "Predicted Answer: Hackers\n",
      "\n",
      "Question 13: What is the potential to solve some of the world's most pressing problems?\n",
      "Context: or cause financial damage. Protecting against cyber threats requires constant innovation in\n",
      "security technologies, as well as collaboration between governments, businesses, and individuals to\n",
      "ensure that data is secure and that privacy is maintained.\n",
      "The rapid pace of technological change also presents challenges for education and workforce\n",
      "development. As new technologies emerge, workers need to acquire new skills to remain\n",
      "competitive in the job market. Education systems must adapt to prepare students for the jobs of the\n",
      "future, which may require a greater focus on STEM (science, technology, engineering, and\n",
      "mathematics) education, as well as the development of critical thinking and problem-solving skills.\n",
      "Lifelong learning and upskilling will become increasingly important as technology continues to\n",
      "evolve.\n",
      "One of the most exciting aspects of technology is its potential to solve some of the world's most\n",
      "pressing problems. From addressing climate change to improving access to education and\n",
      "healthcare, techno\n",
      "Predicted Answer: One of the most exciting aspects of technology\n",
      "\n",
      "Question 14: What is the key to harnessing technology's potential?\n",
      "Context: logy has the power to create positive change on a global scale. However, it is\n",
      "important to approach technological innovation with caution, ensuring that it is used ethically and\n",
      "responsibly to benefit society as a whole.\n",
      "As we look to the future, it is clear that technology will continue to evolve and shape the world in\n",
      "ways we can only begin to imagine. The key to harnessing its potential lies in our ability to balance\n",
      "progress with responsibility, ensuring that the benefits of technology are shared by all and that its\n",
      "challenges are addressed in a thoughtful and inclusive manner.\n",
      "The evolution of technology has been one of the most significant factors shaping human history.\n",
      "From the advent of the wheel to the rise of artificial intelligence (AI), technology has played a pivotal\n",
      "role in the progress of society. In ancient times, humans developed basic tools to make their lives\n",
      "easier, but it was during the industrial revolution that technological advancements began to rapidlytransform the world. The inventi\n",
      "Predicted Answer: The key to harnessing its potential lies in our ability to balance progress with responsibility\n",
      "\n",
      "Question 15: What was the invention of the telephone, radio, and television?\n",
      "Context: on of the steam engine, for example, revolutionized transportation\n",
      "and industry, leading to an era of mass production and global trade.\n",
      "The 20th century saw an explosion of technological breakthroughs. The invention of the telephone,\n",
      "radio, and television changed the way humans communicated and interacted. The development of\n",
      "computers and the internet has been equally transformative, enabling a level of connectivity and\n",
      "information-sharing that was previously unimaginable. Today, we are living in an age of digital\n",
      "technology, where smartphones, cloud computing, and artificial intelligence are integral parts of daily\n",
      "life.\n",
      "Artificial intelligence is one of the most exciting and rapidly evolving fields in technology today. AI\n",
      "refers to machines that can perform tasks that typically require human intelligence, such as learning,\n",
      "reasoning, and problem-solving. AI systems can analyze vast amounts of data to identify patterns\n",
      "and make predictions, which has applications in fields ranging from healthcare to finance \n",
      "Predicted Answer: changed the way humans communicated and interacted\n",
      "\n",
      "Question 16: What is the potential of AI to improve efficiency?\n",
      "Context: to\n",
      "entertainment. The potential of AI to improve efficiency and solve complex problems is vast, but it\n",
      "also raises important ethical and societal questions about privacy, job displacement, and the control\n",
      "of autonomous systems.\n",
      "One area where technology is making a major impact is in healthcare. Advances in medical\n",
      "technology, such as robotic surgery, diagnostic imaging, and telemedicine, are improving patient\n",
      "outcomes and making healthcare more accessible. Additionally, biotechnology and genomics are\n",
      "opening up new possibilities for personalized medicine, allowing for treatments tailored to an\n",
      "individual's genetic makeup. These technologies hold great promise, but they also present\n",
      "challenges, such as ensuring equitable access and addressing concerns about privacy and data\n",
      "security.\n",
      "The internet of things (IoT) is another technological development that is transforming the way welive. IoT refers to the network of connected devices that communicate with each other and share\n",
      "data. Smart homes, wearable devices,\n",
      "Predicted Answer: The answer is unclear, please try again.\n",
      "\n",
      "Question 17: What is the potential for automation and robotics to increase efficiency?\n",
      "Context:  and connected cars are all examples of IoT applications.\n",
      "These technologies are making life more convenient and efficient, but they also raise concerns\n",
      "about security and the potential for privacy violations. As IoT devices become more ubiquitous, it will\n",
      "be crucial to ensure that they are secure and that user data is protected.\n",
      "The rise of automation and robotics is another major technological trend that is reshaping industries\n",
      "around the world. Robots are increasingly being used in manufacturing, agriculture, and even\n",
      "healthcare to perform tasks that were once done by humans. While automation has the potential to\n",
      "increase efficiency and reduce costs, it also raises concerns about job displacement and the future\n",
      "of work. As robots and AI systems take on more tasks, it will be important to find ways to retrain\n",
      "workers and ensure that they have the skills needed for the jobs of the future.\n",
      "In the realm of energy, renewable energy technologies are advancing rapidly. Solar and wind power\n",
      "are becoming more affor\n",
      "Predicted Answer: The answer is unclear, please try again.\n",
      "\n",
      "Question 18: What is the potential for space exploration to unlock?\n",
      "Context: dable and efficient, and new technologies like energy storage and smart\n",
      "grids are helping to integrate these renewable sources into the existing energy infrastructure. The\n",
      "shift toward renewable energy is crucial in the fight against climate change, but it also presents\n",
      "challenges, such as the need for investment in new infrastructure and the potential impact on\n",
      "traditional energy industries.\n",
      "Space exploration is another area where technology is making significant strides. Advances in\n",
      "rocket technology, satellite communication, and space telescopes are allowing humans to explore\n",
      "the cosmos like never before. Private companies like SpaceX are making space travel more\n",
      "affordable and accessible, with the goal of eventually enabling human settlement on other planets.\n",
      "The potential for space exploration to unlock new scientific discoveries and resources is immense,\n",
      "but it also presents challenges, such as the ethical implications of colonizing other planets and the\n",
      "environmental impact of space exploration.\n",
      "Predicted Answer: new scientific discoveries and resources\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"technology_paragraphs_removed.pdf\"\n",
    "\n",
    "qa_pairs = process_pdf_and_generate_questions_with_context(pdf_path, model, tokenizer)\n",
    "\n",
    "for i, qa in enumerate(qa_pairs, 1):\n",
    "    print(f\"Question {i}: {qa['question']}\")\n",
    "    print(f\"Context: {qa['context']}\")\n",
    "    print(f\"Predicted Answer: {qa['answer']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
